# version: '3.8' # Removed by user, keeping it removed.

services:
  frontend:
    build: ./frontend
    ports:
      - "5173:5173"
    volumes:
      - ./frontend:/app
      - /app/node_modules # Cache node_modules
    environment:
      - VITE_API_BASE_URL=http://backend:8000 # Frontend (in Docker) to Backend (in Docker)
      - CHOKIDAR_USEPOLLING=true # For hot reloading in some environments
    depends_on:
      - backend
    networks:
      - app-network

  backend:
    build: ./backend
    ports:
      - "8000:8000" # Expose backend's internal port 8000 to host port 8000
    volumes:
      - ./backend:/app # Mount backend code
    environment:
      # Updated to use local services
      - OLLAMA_BASE_URL=http://host.docker.internal:11434 # For backend to access Ollama on host
      - CHROMA_HOST=host.docker.internal # ChromaDB running locally on host
      - CHROMA_PORT=8000 # ChromaDB local port
      - EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2
      - OLLAMA_MODEL=llama3 # Ensure this is consistent with your config.py (OLLAMA_MODEL_FOR_RAG)
      # NeMo Guardrails is now integrated into backend, no external service needed
      - USE_GUARDRAILS=false
      # Consider adding LOG_LEVEL=INFO if needed from previous versions
    networks:
      - app-network
    # Add extra_hosts if host.docker.internal doesn't work on your Linux distribution
    # for the backend to reach host Ollama (if it needs to directly).
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"
    # Added command to run the backend FastAPI application

networks:
  app-network:
    driver: bridge
